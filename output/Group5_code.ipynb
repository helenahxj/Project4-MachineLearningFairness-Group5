{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## import the required package\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ulwOD5MKpMDQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description\n",
        "\n",
        "The data contains the crimial history jail and prison time, demographics and COMPAS risk scores for defendants from Broward County from 2013 to 2014. The dataset we are using is compas-scores-two-years.csv."
      ],
      "metadata": {
        "id": "7AF9EV21orzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bWg3BXzOn8SK"
      },
      "outputs": [],
      "source": [
        "## Read the file\n",
        "df = pd.read_csv(\"/content/compas-scores-two-years.csv\")\n",
        "\n",
        "## Filter the data\n",
        "df = df[(df[\"race\"] == \"African-American\") | (df[\"race\"] == \"Caucasian\")]\n",
        "\n",
        "## Change the race entry\n",
        "df[\"race\"] = np.where(df[\"race\"] == \"African-American\", 0, 1)\n",
        "\n",
        "## We clean up the data such that some attribute that is clearly independent\n",
        "## with the two_year_recid, ie. name, id\n",
        "df.drop([\"id\", \"name\", \"first\", \"last\"], axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper 1: Handling Conditional Discrimination\n",
        "\n",
        "This paper handle with discrimination introduced by sensitive parameter, here \"race\".\n",
        "\n",
        "### Background\n",
        "\n",
        "The bias that caused by discrimination can be distribute to two part:\n",
        "- discrimination caused by the sensitive attribute itself $D_{bad}$\n",
        "- the discrimination caused by the attributes that are correlated to the sensitive attribute $D_{expl}$.\n",
        "\n",
        "*Notice* : the attribute that are correlated to the sensitive attribute and also gives some objective information to the label y is called **explanatory attribute**.\n",
        "\n",
        "In summary, $D_{all}=D_{bad}+D_{expl}$.\n",
        "\n",
        "### Objective of the paper\n",
        "\n",
        "- minimize the absolute value of $D_{bad}$\n",
        "- keeping the accuracy as high as possible\n",
        "\n",
        "### Method\n",
        "\n",
        "To be discrimination free, we should control:\n",
        "- $P_c(+|e_i, race = 0) = P_c(+|e_i, race = 1)$, where $e_i$ is the explanatory attribute and $P(+)=P(y=+1)$\n",
        "- $P_c(+|e_i) = P_c^\\star(+|e_i)$, where $P_c^\\star(+|e_i):=\\frac{P_c(+|e_i, race=1)+P_c(+|e_i, race=0)}{2}$\n",
        "\n",
        "To achieve it, the paper introduced two methods: Local Massaging and Local Preferential Sampling.\n",
        "\n",
        "##### *Local Massaging*\n",
        "\n",
        "Modify the value of y until $P_c'(+|e_i, race = 0)=P_c'(+|e_i, race = 1)=P_c^\\star(+|e_i)$ by identifing the instances that are close to the decision boundary and changes the values of their labels to the opposite.\n",
        "\n",
        "Convert the original binary label y into real valued probabilities of defendant recidivated within two year, and sort the value. Change the lable of individuals that are almost recidivated within two year or almost not recidivated within two year to opposite.\n",
        "\n",
        "##### *Local Preferential Sampling*\n",
        "\n",
        "This method modifies the composition of the training set. It deletes and duplicates training instances such that the modified training set satisty $P_c'(+|e_i, race = 0)=P_c'(+|e_i, race = 1)=P_c^\\star(+|e_i)$.\n",
        "\n",
        "To achieve it, it deletes the ‘wrong’ instances that are close to the decision boundary and duplicates the instances that are ‘right’ and close to the boundary."
      ],
      "metadata": {
        "id": "7JkUP0x9suGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Calculate D_{all}\n",
        "P_y1r1 = len(df[(df[\"two_year_recid\"] == 1) & (df[\"race\"] == 1)])/len(df)\n",
        "P_y1r0 = len(df[(df[\"two_year_recid\"] == 1) & (df[\"race\"] == 0)])/len(df)\n",
        "D_all = P_y1r1-P_y1r0"
      ],
      "metadata": {
        "id": "ahHLuCvLqbOZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jFMhudq3W5q",
        "outputId": "7f2e35b5-d6c9-4ac3-9918-da451feec542"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.15203252032520323"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}