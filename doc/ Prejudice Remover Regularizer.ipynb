{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "159dcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the required package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9ef575b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the file\n",
    "df = pd.read_csv(\"../data/compas-scores-two-years.csv\")\n",
    "\n",
    "## Filter the data\n",
    "df = df[(df[\"race\"] == \"African-American\") | (df[\"race\"] == \"Caucasian\")]\n",
    "\n",
    "## Change the race entry\n",
    "df[\"race\"] = np.where(df[\"race\"] == \"African-American\", 0, 1)\n",
    "\n",
    "## We drop attributes that is clearly independent with the two_year_recid, ie. name, id, r_case_number, c_case_number,\n",
    "## as well as the attribute with all NaN value\n",
    "## as well as the duplicate columns\n",
    "df.drop([\"id\", \"name\", \"first\", \"last\", \"r_case_number\", \"c_case_number\",\n",
    "         \"violent_recid\",\n",
    "         \"decile_score.1\", \"priors_count.1\"],\n",
    "        axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3ea75391",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We drop the column with the number of NaN value exceed 1000\n",
    "df.drop([\"vr_charge_desc\", \"vr_offense_date\",\n",
    "        \"vr_charge_degree\", \"vr_case_number\", \"c_arrest_date\",\n",
    "        \"c_arrest_date\", \"r_jail_out\", \"r_jail_in\", \"r_days_from_arrest\",\n",
    "        \"r_charge_desc\", \"r_charge_degree\", \"r_offense_date\"],\n",
    "        axis = 1, inplace=True)\n",
    "\n",
    "## Remove the rows with NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "## we also drop the columns represent the date\n",
    "df.drop(['compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out',\n",
    "         'c_offense_date', 'screening_date', 'v_screening_date',\n",
    "         'in_custody', 'out_custody'],\n",
    "        axis = 1, inplace=True)\n",
    "\n",
    "## We drop the somehow repeated attribute, age_cat, score_text, v_score_text\n",
    "df.drop(['age_cat', 'score_text', 'v_score_text'],\n",
    "        axis = 1, inplace=True)\n",
    "\n",
    "## Set sex into 0 or 1, c_charge_degree into 0 or 1\n",
    "df[\"sex\"] = np.where(df[\"sex\"] == \"Male\", 0, 1)\n",
    "df[\"c_charge_degree\"] = np.where(df[\"c_charge_degree\"] == \"M\", 0, 1)\n",
    "\n",
    "## Drop the column with only 1 input or too many category\n",
    "df.drop(['type_of_assessment', 'v_type_of_assessment', 'c_charge_desc'],\n",
    "        axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fee69fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>428.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  race  juv_fel_count  decile_score  juv_misd_count  \\\n",
       "1    0   34     0              0             3               0   \n",
       "2    0   24     0              0             4               0   \n",
       "6    0   41     1              0             6               0   \n",
       "8    1   39     1              0             1               0   \n",
       "9    0   21     1              0             3               0   \n",
       "\n",
       "   juv_other_count  priors_count  days_b_screening_arrest  c_days_from_compas  \\\n",
       "1                0             0                     -1.0                 1.0   \n",
       "2                1             4                     -1.0                 1.0   \n",
       "6                0            14                     -1.0                 1.0   \n",
       "8                0             0                     -1.0                 1.0   \n",
       "9                0             1                    428.0               308.0   \n",
       "\n",
       "   c_charge_degree  is_recid  is_violent_recid  v_decile_score  start  end  \\\n",
       "1                1         1                 1               1      9  159   \n",
       "2                1         1                 0               3      0   63   \n",
       "6                1         1                 0               2      5   40   \n",
       "8                0         0                 0               1      2  747   \n",
       "9                1         1                 1               5      0  428   \n",
       "\n",
       "   event  two_year_recid  \n",
       "1      1               1  \n",
       "2      0               1  \n",
       "6      1               1  \n",
       "8      0               0  \n",
       "9      1               1  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "00e5c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.100100\n",
      "Accuracy: 0.989980\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X, y = df.drop(\"two_year_recid\", axis = 1, inplace = False), df.two_year_recid\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=5243)\n",
    "\n",
    "\n",
    "baseline = LogisticRegression(random_state=5243,max_iter=1000)\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "preds = baseline.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "preds_all = baseline.predict(X_test)\n",
    "accuracy = sum(y_test == preds_all)/len(y_test)\n",
    "print(\"Accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d81f5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "#1\n",
    "df_1 = df.loc[df['two_year_recid']==1]\n",
    "X_1, y_1 = df_1.drop(\"two_year_recid\", axis = 1, inplace = False), df_1.two_year_recid\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.2, random_state=5243)\n",
    "\n",
    "x_1 = t.from_numpy(np.array(X_train_1)).to(t.float32)\n",
    "y_1 = t.from_numpy(np.array(y_train_1).astype('float32')).reshape(x_1.shape[0],1)\n",
    "\n",
    "x_test_1 = t.from_numpy(np.array(X_test_1)).to(t.float32)\n",
    "y_test_1 = t.from_numpy(np.array(y_test_1).astype('float32')).reshape(x_test_1.shape[0],1)\n",
    "\n",
    "#0\n",
    "df_0 = df.loc[df['two_year_recid']==0]\n",
    "X_0, y_0 = df_0.drop(\"two_year_recid\", axis = 1, inplace = False), df_0.two_year_recid\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.2, random_state=5243)\n",
    "\n",
    "x_0 = t.from_numpy(np.array(X_train_0)).to(t.float32)\n",
    "y_0 = t.from_numpy(np.array(y_train_0).astype('float32')).reshape(x_0.shape[0],1)\n",
    "\n",
    "x_test_0 = t.from_numpy(np.array(X_test_0)).to(t.float32)\n",
    "y_test_0 = t.from_numpy(np.array(y_test_0).astype('float32')).reshape(x_test_0.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "526f67ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,  28.,   1.,  ...,  44., 792.,   0.],\n",
       "        [  1.,  54.,   1.,  ...,   0., 921.,   0.],\n",
       "        [  1.,  25.,   1.,  ...,   0., 827.,   0.],\n",
       "        ...,\n",
       "        [  1.,  20.,   1.,  ...,   0., 921.,   0.],\n",
       "        [  0.,  25.,   0.,  ...,   1., 758.,   0.],\n",
       "        [  0.,  23.,   0.,  ...,   0., 870.,   0.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "50359549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # out_features is the number of outputs. I don't use bias here because the constant dimension in x already introduced the bias term in W.\n",
    "        self.w = nn.Linear(x_1.shape[1], out_features=1, bias=True)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        # For the torch.nn.NLLLoss, the first input is the \"log probability\",log_softmax? log sigmod(binary).\n",
    "        w = self.w(x)\n",
    "        output = self.sigmod(w)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7c3d6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRLoss():#using linear\n",
    "    def __init__(self, eta=1.0):\n",
    "        super(PRLoss, self).__init__()\n",
    "        self.eta = eta\n",
    "    def forward(self,output_1,output_0):\n",
    "        # For the mutual information, \n",
    "        # Pr[y|s] = sum{(xi,si),si=s} sigma(xi,si) / #D[xs]\n",
    "        #D[xs]\n",
    "        N_1 = t.tensor(output_1.shape[0])\n",
    "        N_0   = t.tensor(output_0.shape[0])\n",
    "        Dxisi = t.stack((N_0,N_1),axis=0)\n",
    "        # Pr[y|s]\n",
    "        y_pred_1 = t.sum(output_1)\n",
    "        y_pred_0   = t.sum(output_0)\n",
    "        P_ys = t.stack((y_pred_0,y_pred_1),axis=0) / Dxisi\n",
    "        # Pr[y]\n",
    "        P = t.cat((output_1,output_0),0)\n",
    "        P_y = t.sum(P) / (x_1.shape[0]+x_0.shape[0])\n",
    "        # P(siyi)\n",
    "        P_s1y1 = t.log(P_ys[1]) - t.log(P_y)\n",
    "        P_s1y0 = t.log(1-P_ys[1]) - t.log(1-P_y)\n",
    "        P_s0y1 = t.log(P_ys[0]) - t.log(P_y)\n",
    "        P_s0y0 = t.log(1-P_ys[0]) - t.log(1-P_y)\n",
    "        # PI\n",
    "        PI_s1y1 = output_1 * P_s1y1\n",
    "        PI_s1y0 =(1- output_1) * P_s1y0\n",
    "        PI_s0y1 = output_0 * P_s0y1\n",
    "        PI_s0y0 = (1- output_0 )* P_s0y0\n",
    "        PI = t.sum(PI_s1y1) + t.sum(PI_s1y0) + t.sum(PI_s0y1) + t.sum(PI_s0y0)\n",
    "        PI = self.eta * PI\n",
    "        return PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f76e5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy( Model_1,Model_0, x_1, y_1,x_0,y_0):\n",
    "    y1_pred = (Model_1(x_1) >= 0.5)\n",
    "    y0_pred = (Model_0(x_0) >= 0.5)\n",
    "    accu_1  = t.sum(y1_pred.flatten() == y_1.flatten()) / x_1.shape[0]\n",
    "    accu_0  = t.sum(y0_pred.flatten() == y_0.flatten()) / x_0.shape[0]\n",
    "    accuracy = (accu_1 + accu_0) / 2\n",
    "    return round(accuracy.item(),4)\n",
    "    print(\"Accuracy : %.3f\" % (accuracy * 100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "da18aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRLR():#using linear\n",
    "    def __init__(self, eta=0.0,epochs = 3000,lr = 0.01):\n",
    "        super(PRLR, self).__init__()\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "    def fit(self,x_1,y_1,x_0,y_0,x_test_1,y_test_1,x_test_0,y_test_0):\n",
    "        model_1 = LogisticRegression()\n",
    "        model_0 = LogisticRegression()\n",
    "        criterion = nn.BCELoss(reduction='sum')\n",
    "        PI = PRLoss(eta=self.eta)\n",
    "        epochs = self.epochs\n",
    "        optimizer = t.optim.Adam(list(model_1.parameters())+ list(model_0.parameters()), self.lr, weight_decay=1e-5)\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            output_1 = model_1(x_1)\n",
    "            output_0 = model_0(x_0)\n",
    "            logloss = criterion(output_1, y_1)+ criterion(output_0, y_0)\n",
    "            PIloss = PI.forward(output_1,output_0)\n",
    "            loss = PIloss +logloss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model_1.eval()\n",
    "        model_0.eval()\n",
    "        accu = accuracy(model_1,model_0,x_test_1,y_test_1,x_test_0,y_test_0)\n",
    "        return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ae0f9de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9990000128746033\n"
     ]
    }
   ],
   "source": [
    "PR = PRLR(eta = 1.0, epochs = 1000, lr = 0.01)\n",
    "\n",
    "accv=t.tensor(PR.fit(x_1,y_1,x_0,y_0,x_test_1,y_test_1,x_test_0,y_test_0))\n",
    "print(\"accuracy:\",float(accv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c2664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
