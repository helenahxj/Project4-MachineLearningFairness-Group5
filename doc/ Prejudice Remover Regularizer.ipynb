{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "159dcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the required package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9ef575b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the file\n",
    "df = pd.read_csv(\"../data/compas-scores-two-years.csv\")\n",
    "\n",
    "## Filter the data\n",
    "df = df[(df[\"race\"] == \"African-American\") | (df[\"race\"] == \"Caucasian\")]\n",
    "\n",
    "## Change the race entry\n",
    "df[\"race\"] = np.where(df[\"race\"] == \"African-American\", 0, 1)\n",
    "\n",
    "## We drop attributes that is clearly independent with the two_year_recid, ie. name, id, r_case_number, c_case_number,\n",
    "## as well as the attribute with all NaN value\n",
    "## as well as the duplicate columns\n",
    "df.drop([\"id\", \"name\", \"first\", \"last\", \"r_case_number\", \"c_case_number\",\n",
    "         \"violent_recid\",\n",
    "         \"decile_score.1\", \"priors_count.1\"],\n",
    "        axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3ea75391",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['vr_charge_desc', 'vr_offense_date', 'vr_charge_degree', 'vr_case_number', 'c_arrest_date', 'c_arrest_date', 'r_jail_out', 'r_jail_in', 'r_days_from_arrest', 'r_charge_desc', 'r_charge_degree', 'r_offense_date'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [316]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## We drop the column with the number of NaN value exceed 1000\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvr_charge_desc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvr_offense_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvr_charge_degree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvr_case_number\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc_arrest_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc_arrest_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_jail_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_jail_in\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_days_from_arrest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_charge_desc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_charge_degree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_offense_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m## Remove the rows with NaN\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['vr_charge_desc', 'vr_offense_date', 'vr_charge_degree', 'vr_case_number', 'c_arrest_date', 'c_arrest_date', 'r_jail_out', 'r_jail_in', 'r_days_from_arrest', 'r_charge_desc', 'r_charge_degree', 'r_offense_date'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## We drop the column with the number of NaN value exceed 1000\n",
    "df.drop([\"vr_charge_desc\", \"vr_offense_date\",\n",
    "        \"vr_charge_degree\", \"vr_case_number\", \"c_arrest_date\",\n",
    "        \"c_arrest_date\", \"r_jail_out\", \"r_jail_in\", \"r_days_from_arrest\",\n",
    "        \"r_charge_desc\", \"r_charge_degree\", \"r_offense_date\"],\n",
    "        axis = 1, inplace=True)\n",
    "\n",
    "## Remove the rows with NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "## we also drop the columns represent the date\n",
    "df.drop(['compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out',\n",
    "         'c_offense_date', 'screening_date', 'v_screening_date',\n",
    "         'in_custody', 'out_custody', 'days_b_screening_arrest'],\n",
    "        axis = 1, inplace=True)\n",
    "\n",
    "## We drop the somehow repeated attribute, age_cat, score_text, v_score_text\n",
    "df.drop(['age_cat', 'score_text', 'v_score_text', 'is_recid', \"v_decile_score\"],\n",
    "        axis = 1, inplace=True)\n",
    "\n",
    "## Set sex into 0 or 1, c_charge_degree into 0 or 1\n",
    "df[\"sex\"] = np.where(df[\"sex\"] == \"Male\", 0, 1)\n",
    "df[\"c_charge_degree\"] = np.where(df[\"c_charge_degree\"] == \"M\", 0, 1)\n",
    "\n",
    "## Drop the column with only 1 input or too many category\n",
    "df.drop(['type_of_assessment', 'v_type_of_assessment', 'c_charge_desc'],\n",
    "        axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fee69fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  race  juv_fel_count  decile_score  juv_misd_count  \\\n",
       "1    0   34     0              0             3               0   \n",
       "2    0   24     0              0             4               0   \n",
       "6    0   41     1              0             6               0   \n",
       "8    1   39     1              0             1               0   \n",
       "9    0   21     1              0             3               0   \n",
       "\n",
       "   juv_other_count  priors_count  c_days_from_compas  c_charge_degree  \\\n",
       "1                0             0                 1.0                1   \n",
       "2                1             4                 1.0                1   \n",
       "6                0            14                 1.0                1   \n",
       "8                0             0                 1.0                0   \n",
       "9                0             1               308.0                1   \n",
       "\n",
       "   is_violent_recid  start  end  event  two_year_recid  \n",
       "1                 1      9  159      1               1  \n",
       "2                 0      0   63      0               1  \n",
       "6                 0      5   40      1               1  \n",
       "8                 0      2  747      0               0  \n",
       "9                 1      0  428      1               1  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "00e5c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.219308\n",
      "Accuracy: 0.951904\n",
      "discriminatioin 0.13598888652499458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "scaler = StandardScaler()\n",
    "X, y = df.drop(\"two_year_recid\", axis = 1, inplace = False), df.two_year_recid\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=5243)\n",
    "\n",
    "\n",
    "baseline = LogisticRegression(random_state=5243,max_iter=1000)\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "preds = baseline.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "preds_all = baseline.predict(X_test)\n",
    "accuracy = sum(y_test == preds_all)/len(y_test)\n",
    "print(\"Accuracy: %f\" % (accuracy))\n",
    "\n",
    "## Calculate D_{all}\n",
    "def D_all_func(data = df):\n",
    "    P_y1r1 = len(data[(data[\"two_year_recid\"] == 1) & (data[\"race\"] == 1)])/len(data[data['race'] == 1])\n",
    "    P_y1r0 = len(data[(data[\"two_year_recid\"] == 1) & (data[\"race\"] == 0)])/len(data[data['race'] == 0])\n",
    "    D_all = P_y1r0-P_y1r1\n",
    "    return(D_all)\n",
    "\n",
    "D_all_base = D_all_func()\n",
    "print(\"discriminatioin\",D_all_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d81f5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "#1\n",
    "df_1 = df.loc[df['two_year_recid']==1]\n",
    "X_1, y_1 = df_1.drop(\"two_year_recid\", axis = 1, inplace = False), df_1.two_year_recid\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.2, random_state=5243)\n",
    "\n",
    "x_1 = t.from_numpy(np.array(X_train_1)).to(t.float32)\n",
    "y_1 = t.from_numpy(np.array(y_train_1).astype('float32')).reshape(x_1.shape[0],1)\n",
    "\n",
    "x_test_1 = t.from_numpy(np.array(X_test_1)).to(t.float32)\n",
    "y_test_1 = t.from_numpy(np.array(y_test_1).astype('float32')).reshape(x_test_1.shape[0],1)\n",
    "\n",
    "#0\n",
    "df_0 = df.loc[df['two_year_recid']==0]\n",
    "X_0, y_0 = df_0.drop(\"two_year_recid\", axis = 1, inplace = False), df_0.two_year_recid\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.2, random_state=5243)\n",
    "\n",
    "x_0 = t.from_numpy(np.array(X_train_0)).to(t.float32)\n",
    "y_0 = t.from_numpy(np.array(y_train_0).astype('float32')).reshape(x_0.shape[0],1)\n",
    "\n",
    "x_test_0 = t.from_numpy(np.array(X_test_0)).to(t.float32)\n",
    "y_test_0 = t.from_numpy(np.array(y_test_0).astype('float32')).reshape(x_test_0.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "526f67ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,  28.,   1.,  ...,  44., 792.,   0.],\n",
       "        [  1.,  54.,   1.,  ...,   0., 921.,   0.],\n",
       "        [  1.,  25.,   1.,  ...,   0., 827.,   0.],\n",
       "        ...,\n",
       "        [  1.,  20.,   1.,  ...,   0., 921.,   0.],\n",
       "        [  0.,  25.,   0.,  ...,   1., 758.,   0.],\n",
       "        [  0.,  23.,   0.,  ...,   0., 870.,   0.]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7c3d6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRLoss():\n",
    "    def __init__(self, eta=1.0):\n",
    "        super(PRLoss, self).__init__()\n",
    "        self.eta = eta\n",
    "    def forward(self,output_1,output_0):\n",
    "        N_1 = t.tensor(output_1.shape[0])\n",
    "        N_0   = t.tensor(output_0.shape[0])\n",
    "        Dxisi = t.stack((N_0,N_1),axis=0)\n",
    "\n",
    "        y_pred_1 = t.sum(output_1)\n",
    "        y_pred_0 = t.sum(output_0)\n",
    "        P_ys = t.stack((y_pred_0,y_pred_1),axis=0) / Dxisi\n",
    "\n",
    "        P = t.cat((output_1,output_0),0)\n",
    "        P_y = t.sum(P) / (x_1.shape[0]+x_0.shape[0])\n",
    "\n",
    "        P_s1y1 = t.log(P_ys[1]) - t.log(P_y)\n",
    "        P_s1y0 = t.log(1-P_ys[1]) - t.log(1-P_y)\n",
    "        P_s0y1 = t.log(P_ys[0]) - t.log(P_y)\n",
    "        P_s0y0 = t.log(1-P_ys[0]) - t.log(1-P_y)\n",
    "\n",
    "        PI_s1y1 = output_1 * P_s1y1\n",
    "        PI_s1y0 =(1- output_1) * P_s1y0\n",
    "        PI_s0y1 = output_0 * P_s0y1\n",
    "        PI_s0y0 = (1- output_0 )* P_s0y0\n",
    "        PI = t.sum(PI_s1y1) + t.sum(PI_s1y0) + t.sum(PI_s0y1) + t.sum(PI_s0y0)\n",
    "        PI = self.eta * PI\n",
    "        return PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f76e5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy( Model_1,Model_0, x_1, y_1,x_0,y_0):\n",
    "    y1_pred = (Model_1(x_1) >= 0.5)\n",
    "    y0_pred = (Model_0(x_0) >= 0.5)\n",
    "    accu_1  = t.sum(y1_pred.flatten() == y_1.flatten()) / x_1.shape[0]\n",
    "    accu_0  = t.sum(y0_pred.flatten() == y_0.flatten()) / x_0.shape[0]\n",
    "    accuracy = (accu_1 + accu_0) / 2\n",
    "    return round(accuracy.item(),6),y1_pred,y0_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "da18aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()        \n",
    "        self.w = nn.Linear(x_1.shape[1], out_features=1, bias=True)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        w = self.w(x)\n",
    "        output = self.sigmod(w)\n",
    "        return output\n",
    "    \n",
    "class PRLR():#using linear\n",
    "    def __init__(self, eta=1.0,epochs = 3000,lr = 0.01):\n",
    "        super(PRLR, self).__init__()\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.model_1 = LogisticRegression()\n",
    "        self.model_0 = LogisticRegression()\n",
    "    def fit(self,x_1,y_1,x_0,y_0,x_test_1,y_test_1,x_test_0,y_test_0):\n",
    "        criterion = nn.BCELoss(reduction='sum')\n",
    "        PI = PRLoss(eta=self.eta)\n",
    "        epochs = self.epochs\n",
    "        optimizer = t.optim.Adam(list(self.model_1.parameters())+ list(self.model_0.parameters()), self.lr, weight_decay=1e-5)\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            output_1 = self.model_1(x_1)\n",
    "            output_0 = self.model_0(x_0)\n",
    "            self.output=output_1\n",
    "            logloss = criterion(output_1, y_1)+ criterion(output_0, y_0)\n",
    "            PIloss = PI.forward(output_1,output_0)\n",
    "            loss = PIloss +logloss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        self.model_1.eval()\n",
    "        self.model_0.eval()\n",
    "        accu,y1_pred,y0_pred= accuracy(self.model_1,self.model_0,x_test_1,y_test_1,x_test_0,y_test_0)\n",
    "        return accu,y1_pred,y0_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ae0f9de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0 discriminatioin 0.1193639892505225\n",
      "accuracy: 1.0 discriminatioin 0.1193639892505225\n",
      "accuracy: 0.504193 discriminatioin 0.0026251617398228323\n",
      "accuracy: 0.5 discriminatioin 0.0\n",
      "accuracy: 0.477012 discriminatioin -0.013250223947446998\n",
      "accuracy: 0.502096 discriminatioin 0.00338409475465313\n",
      "accuracy: 0.723867 discriminatioin -0.11331740818154673\n",
      "accuracy: 0.265127 discriminatioin -0.15303075544938788\n",
      "accuracy: 0.204005 discriminatioin -0.18435851497959588\n",
      "accuracy: 0.480843 discriminatioin 0.004839753160147307\n",
      "accuracy: 0.60972 discriminatioin 0.0123419926346173\n",
      "accuracy: 0.466746 discriminatioin -0.04110679804916889\n"
     ]
    }
   ],
   "source": [
    "eta_list=[0.0,1.0,2.0,3.0,4.0,5.0,10.0,15.0,20.0,25.0,30.0,80.0]\n",
    "for i in range(len(eta_list)):\n",
    "    PR = PRLR(eta = eta_list[i], epochs = 1000, lr = 0.01)\n",
    "    accu,y1_pred,y0_pred=PR.fit(x_1,y_1,x_0,y_0,x_test_1,y_test_1,x_test_0,y_test_0)\n",
    "    df_x_test_1 = pd.DataFrame(x_test_1, columns=df.columns[:-1])\n",
    "    df_x_test_0 = pd.DataFrame(x_test_0, columns=df.columns[:-1])\n",
    "    df_features = pd.concat([df_x_test_1, df_x_test_0], axis=0).reset_index(drop=True)\n",
    "\n",
    "    df_y_pred = pd.DataFrame(np.vstack((y1_pred, y0_pred)), columns=['two_year_recid'])\n",
    "    final_df = pd.concat([df_features, df_y_pred], axis=1)\n",
    "    \n",
    "    D_all_base = D_all_func(data=final_df)\n",
    "    \n",
    "    print(\"accuracy:\",float(accu), end=\" \")\n",
    "    print(\"discrimination\",D_all_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e10ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
